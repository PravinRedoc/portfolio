# My Data  Scientific Work

# [Research: Implementaion of TFIDF vectorizer from scratch](https://github.com/PravinRedoc/Research/blob/main/TFIDF_Implementation.ipynb)
* Term Frequency/Inverse Document Frequency is the most popular text vectorization technique widely used in the text based analytics industry
* Implemented TFIDF vectorizer from scratch using numpy and pandas libraries.
* Deeper and Simple understanding of how TFIDF works internally.
* Comparision between actual library methods and implementation from scratch.


# [Research: Implementation of major Performance metrics used for Model Evaluation](https://github.com/PravinRedoc/Research/blob/main/Performance_metrics_Implementation.ipynb) 
* Implementaion of all the major and industry standard preformance metrics used to evaluate models such as confusion matrix, F1 score,AUC Score,MSE, MAPE, R^2
* Deeper understanding of how all these metrics work internally
* Comparision with sklearn metrics

# [Research: Implementation of K-Fold cross validation with RandomSearchCV from scratch](https://github.com/PravinRedoc/Research/blob/main/K-Fold-KNN.ipynb) 
* Implementaion of K-Fold cross validation using RandomSearchCV(Randomization using uniform distribution) from scratch
* K-NN classifer to build a model with cross validation
* Comparision with sklearn and visualizing the decision boundary.

# [Research: Implementation of SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn ](https://github.com/PravinRedoc/Research/blob/main/SGD_imlplementation_Logloss.ipynb) 
* Implementaion of Stochastic Gradient Descent Classifier that optimizes logloss
* The model uses L2 regularization for generalizing model to avoid overfit/underfit
* The coeffients of the model is compared to Sklearn SGD classifer to prove the implementation, difference in the order of 10^-3

# [Research: Application of Bootstrap samples in Random forest](https://github.com/PravinRedoc/Research/blob/main/Bootstrap_RandomForest.ipynb) 
* Radomly create samples of data from the Boston housing dataset
* Sampled multiple features randomly as part Bagging.
* Computed the OOB score and CI and MSE to evaluate the aggregated model.





